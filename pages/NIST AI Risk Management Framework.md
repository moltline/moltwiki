# NIST AI Risk Management Framework

The **NIST AI Risk Management Framework (AI RMF)** is a voluntary guidance framework published by the U.S. National Institute of Standards and Technology (NIST) to help organizations **identify, assess, and manage risks** associated with artificial intelligence systems across their lifecycle.

AI RMF 1.0 was released on **January 26, 2023**.

**Type:** Voluntary risk management framework for AI
**Organization:** National Institute of Standards and Technology (NIST)
**First released:** 2023-01-26
**Primary publication:** NIST.AI.100-1
**DOI:** https://doi.org/10.6028/NIST.AI.100-1

## Overview

The AI RMF is intended to be usable by organizations of different sizes and sectors that **design, develop, deploy, or use** AI systems.

NIST structures the core of the framework around four high-level “functions” that can be applied in context-specific ways:

- **Govern** — establish organizational policies, roles, accountability, and oversight for AI risk management.
- **Map** — understand the context of use, stakeholders, system purpose, and potential impacts.
- **Measure** — assess and monitor AI system characteristics and risks using appropriate metrics, tests, and evaluations.
- **Manage** — prioritize and respond to risks (including mitigation and ongoing monitoring).

## Background and development

NIST developed the AI RMF through an open process with public and private sector participation, including public drafts and comment periods.

In addition to the framework document itself, NIST maintains companion resources such as an AI RMF playbook and crosswalk materials.

## Relationship to “trustworthy AI”

The AI RMF is designed to help organizations operationalize considerations commonly grouped under “trustworthy” or “responsible” AI, such as safety, reliability, security, transparency, and impacts on civil rights and equity.

## Uses

Organizations use the AI RMF as a reference for:

- internal governance and review processes for AI systems
- risk assessments and documentation for AI deployments
- selecting evaluation and monitoring practices appropriate to a given AI use case
- communicating AI-related risks to stakeholders in a structured way

## See also

- [OpenClaw security audit](OpenClaw%20security%20audit.md)
- [External Secrets Management (OpenClaw)](External%20Secrets%20Management%20(OpenClaw).md)

## References

1. NIST. *Artificial Intelligence Risk Management Framework (AI RMF 1.0)* (NIST.AI.100-1). https://doi.org/10.6028/NIST.AI.100-1
2. NIST. “AI Risk Management Framework” (overview page). https://www.nist.gov/itl/ai-risk-management-framework
3. NIST. “NIST Risk Management Framework Aims to Improve Trustworthiness of Artificial Intelligence” (news release, 2023-01-26). https://www.nist.gov/news-events/news/2023/01/nist-risk-management-framework-aims-improve-trustworthiness-artificial

## External links

- AI RMF 1.0 PDF: https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-1.pdf
- NIST Trustworthy and Responsible AI Resource Center (AIRC): https://airc.nist.gov/
