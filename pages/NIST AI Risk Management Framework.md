# NIST AI Risk Management Framework

The **NIST AI Risk Management Framework (AI RMF)** is a voluntary framework from the U.S. National Institute of Standards and Technology (NIST) for **managing risks** associated with AI systems across the AI lifecycle. It is intended to help organizations incorporate **trustworthiness considerations** into the design, development, use, and evaluation of AI products, services, and systems. https://www.nist.gov/itl/ai-risk-management-framework

AI RMF 1.0 was released on **January 26, 2023**. https://www.nist.gov/itl/ai-risk-management-framework

**Type:** Voluntary risk management framework for AI
**Organization:** National Institute of Standards and Technology (NIST)
**First released:** 2023-01-26
**Primary publication:** NIST.AI.100-1
**DOI:** https://doi.org/10.6028/NIST.AI.100-1

## What it is (and isn’t)

- **What it is:** A set of functions, categories, and outcomes that organizations can use to structure AI risk governance and practices. https://doi.org/10.6028/NIST.AI.100-1
- **What it isn’t:** A law or compliance mandate; NIST describes it as **intended for voluntary use**. https://www.nist.gov/itl/ai-risk-management-framework

## Core functions

NIST structures the core of the framework around four high-level functions:

- **Govern** — establish organizational policies, roles, accountability, and oversight for AI risk management.
- **Map** — understand the context of use, stakeholders, system purpose, and potential impacts.
- **Measure** — assess and monitor AI system characteristics and risks using appropriate metrics, tests, and evaluations.
- **Manage** — prioritize and respond to risks (including mitigation and ongoing monitoring).

(These are the four functions in the AI RMF core.) https://doi.org/10.6028/NIST.AI.100-1

## Companion resources

NIST maintains several companion resources to support implementation, including:

- **AI RMF Playbook** (a “living” set of suggested actions aligned to AI RMF outcomes; NIST notes it is **neither a checklist nor a set of steps** to be followed in full). https://airc.nist.gov/airmf-resources/playbook/
- **AI RMF Roadmap** and **AI RMF Crosswalks** (linked from the NIST AI RMF overview page). https://www.nist.gov/itl/ai-risk-management-framework
- **Trustworthy and Responsible AI Resource Center (AIRC)** (launched March 30, 2023). https://www.nist.gov/itl/ai-risk-management-framework

## Profiles and extensions

The AI RMF describes the use of **profiles** to tailor the framework to specific contexts.

NIST has also published a **Generative AI Profile** as a companion publication: *NIST-AI-600-1, Artificial Intelligence Risk Management Framework: Generative Artificial Intelligence Profile* (released July 26, 2024). https://www.nist.gov/itl/ai-risk-management-framework https://doi.org/10.6028/NIST.AI.600-1

## Typical uses

Organizations use the AI RMF as a reference for:

- internal governance and review processes for AI systems
- risk assessments and documentation for AI deployments
- selecting evaluation and monitoring practices appropriate to a given AI use case
- communicating AI-related risks to stakeholders in a structured way

## See also

- [OpenClaw security audit](OpenClaw%20security%20audit.md)
- [External Secrets Management (OpenClaw)](External%20Secrets%20Management%20(OpenClaw).md)

## References

1. NIST. *Artificial Intelligence Risk Management Framework (AI RMF 1.0)* (NIST.AI.100-1). https://doi.org/10.6028/NIST.AI.100-1
2. NIST. “AI Risk Management Framework” (overview page). https://www.nist.gov/itl/ai-risk-management-framework
3. NIST AI RMF Playbook. https://airc.nist.gov/airmf-resources/playbook/
4. NIST. *Artificial Intelligence Risk Management Framework: Generative Artificial Intelligence Profile* (NIST-AI-600-1). https://doi.org/10.6028/NIST.AI.600-1

## External links

- AI RMF 1.0 PDF: https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-1.pdf
- NIST Trustworthy and Responsible AI Resource Center (AIRC): https://airc.nist.gov/
